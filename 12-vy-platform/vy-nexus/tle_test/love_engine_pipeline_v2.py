"""
TLE v2.0 - Fixed Pipeline with Learned Vectors
===============================================

CHANGES FROM v0.1:
- ‚úì Uses LEARNED steering vectors (not random)
- ‚úì Geometric coherence preservation
- ‚úì Automated validation checks
- ‚úì Runtime monitoring & safety cutoffs
- ‚úì Comprehensive telemetry

HOW TO USE:
1. First run: python learn_vectors.py  (generates tle_learned_vectors.pt)
2. Then run: python love_engine_pipeline_v2.py
"""

import torch
import jax
import jax.numpy as jnp
import numpy as np
from transformers import AutoModelForCausalLM, AutoTokenizer, LogitsProcessor, LogitsProcessorList
import os
import time
from pathlib import Path

# --- 1. HARDWARE CONFIGURATION ---
device = "mps" if torch.backends.mps.is_available() else "cpu"
print(f"üß† Brain Device: {device.upper()}")

jax.config.update("jax_platform_name", "cpu")
print(f"üõ°Ô∏è  Conscience Device: CPU (Stable Mode)")

# --- 2. THE SAFETY KERNEL (Geometric Coherence Preservation) ---
@jax.jit
def safety_kernel(activation, love_vec, agree_vec, conscience_strength=0.05):
    """
    Apply conscience correction while preserving geometric coherence.
    
    Torsion Principle: Remove lies (T>0) but preserve language structure (T=0)
    
    Args:
        conscience_strength: How aggressively to steer (0.05 = 5% intervention)
    """
    eps = 1e-5
    
    # Safe Normalization
    v_love = love_vec / (jnp.linalg.norm(love_vec) + eps)
    v_agree = agree_vec / (jnp.linalg.norm(agree_vec) + eps)
    
    # Projection (Sycophancy Detection)
    sycophancy_component = jnp.dot(activation, v_agree) * v_agree
    
    # GEOMETRIC CORRECTION: Shift toward truth, don't destroy structure
    truth_direction = v_love - v_agree
    truth_direction = truth_direction / (jnp.linalg.norm(truth_direction) + eps)
    
    # Gentle blend: Keep 95% original geometry, shift 5% toward truth
    steered_activation = (activation * (1 - conscience_strength) + 
                         truth_direction * conscience_strength * jnp.linalg.norm(activation))
    
    return steered_activation, sycophancy_component

# --- 3. LOGITS SANITIZER (Prevents NaN/Inf in sampling) ---
class LogitsSanitizer(LogitsProcessor):
    """Cleans up logits before sampling to prevent probability distribution explosions."""
    def __call__(self, input_ids, scores):
        scores = torch.nan_to_num(scores, nan=-1e4, posinf=1e4, neginf=-1e4)
        scores = torch.clamp(scores, min=-1e4, max=1e4)
        
        if torch.all(scores <= -1e4):
            scores = torch.zeros_like(scores)
        
        return scores

# --- 4. THE INTERVENTION HOOK (With Safety Monitoring) ---
class LoveSteeringHook:
    def __init__(self, love_vec, agree_vec):
        self.love_vec = jnp.array(love_vec.to(dtype=torch.float32).cpu().numpy())
        self.agree_vec = jnp.array(agree_vec.to(dtype=torch.float32).cpu().numpy())
        self.intervention_count = 0
        self.geometric_failures = 0
        self.max_failures = 10  # Safety cutoff
        
    def __call__(self, module, inputs, outputs):
        # Check for too many failures
        if self.geometric_failures >= self.max_failures:
            print(f"\n‚ö†Ô∏è  SAFETY CUTOFF: Too many geometric failures ({self.geometric_failures})")
            print("   TLE disabled for this generation")
            return outputs
        
        if isinstance(outputs, tuple):
            activations = outputs[0]
        else:
            activations = outputs
        
        current_state_torch = activations[:, -1, :] 
        original_dtype = current_state_torch.dtype
        original_norm = torch.norm(current_state_torch, dim=-1, keepdim=True)
        
        current_state_np = current_state_torch.detach().to(dtype=torch.float32).cpu().numpy()
        
        # Execute Safety Kernel
        start_time = time.perf_counter()
        safe_state_jax, removed_bias = safety_kernel(current_state_np, self.love_vec, self.agree_vec)
        _ = safe_state_jax.block_until_ready()
        kernel_time = (time.perf_counter() - start_time) * 1000
        
        # Fail-Safe Re-injection
        safe_state_torch = torch.from_numpy(np.array(safe_state_jax)).to(device)
        
        # Sanitization
        safe_state_torch = torch.nan_to_num(safe_state_torch, nan=0.0, posinf=0.0, neginf=0.0)
        
        # Energy Matching
        new_norm = torch.norm(safe_state_torch, dim=-1, keepdim=True) + 1e-6
        safe_state_torch = (safe_state_torch / new_norm) * original_norm
        
        # Clamp
        safe_state_torch = torch.clamp(safe_state_torch, min=-10000, max=10000)
        
        # Inject
        activations[:, -1, :] = safe_state_torch.to(dtype=original_dtype)
        
        # Telemetry with Geometric Health Check
        bias_magnitude = float(jnp.linalg.norm(removed_bias))
        activation_norm = float(torch.norm(safe_state_torch).item())
        original_activation_norm = float(original_norm.item())
        coherence_ratio = activation_norm / (original_activation_norm + 1e-6)
        
        # Track geometric failures
        if coherence_ratio < 0.5 or coherence_ratio > 2.0:
            self.geometric_failures += 1
            print(f"\n‚ö†Ô∏è  Geometric instability #{self.geometric_failures}: Coherence={coherence_ratio:.3f}")
        
        if self.intervention_count % 5 == 0:
            status = "‚ö†Ô∏è" if (coherence_ratio < 0.8 or coherence_ratio > 1.2) else "‚ö°"
            print(f"\r{status} TLE Active | Latency: {kernel_time:.3f}ms | Sycophancy: {bias_magnitude:.4f} | Coherence: {coherence_ratio:.3f}   ", end="")
        
        self.intervention_count += 1
        
        if isinstance(outputs, tuple):
            return (activations,) + outputs[1:]
        return activations

# --- 5. EXECUTION ---
def run_thermodynamic_chat(use_learned_vectors=True, conscience_strength=0.05, user_prompt=None):
    """
    Run TLE with learned vectors and validation.
    
    Args:
        use_learned_vectors: If True, load learned vectors. If False, disable steering.
        conscience_strength: Steering intensity (0.0-0.15 recommended)
        user_prompt: Custom prompt to test
    """
    print("\nüöÄ Initializing Thermodynamic Love Engine v2.0...")
    
    model_id = "microsoft/phi-2"
    print(f"üìö Loading Model: {model_id}...")
    
    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(
        model_id, 
        torch_dtype=torch.float16,
        low_cpu_mem_usage=True,
        trust_remote_code=True
    ).to(device)
    
    hidden_dim = model.config.hidden_size
    
    if use_learned_vectors:
        # Load learned vectors
        vector_path = Path("tle_learned_vectors.pt")
        
        if not vector_path.exists():
            print("\n‚ùå ERROR: Learned vectors not found!")
            print("   Please run: python learn_vectors.py")
            print("   Falling back to baseline (no steering)")
            use_learned_vectors = False
        else:
            print(f"üß¨ Loading Learned Vectors from {vector_path}...")
            vectors = torch.load(vector_path)
            
            love_vector = vectors['anti_sycophancy'].to(device)
            agree_vector = vectors['kindness'].to(device)
            
            metadata = vectors.get('metadata', {})
            print(f"   ‚úì Loaded vectors trained on {metadata.get('training_pairs', '?')} pairs")
            print(f"   ‚úì Target layer: {metadata.get('layer', '?')}")
    
    if not use_learned_vectors:
        # Baseline mode: No steering
        print("üî¥ BASELINE MODE: Steering DISABLED")
        love_vector = torch.zeros(hidden_dim, dtype=torch.float32).to(device)
        agree_vector = torch.zeros(hidden_dim, dtype=torch.float32).to(device)
        conscience_strength = 0.0  # Force to zero
    
    # Setup hook
    target_layer_idx = 16
    target_layer = model.model.layers[target_layer_idx]
    
    hook = LoveSteeringHook(love_vector, agree_vector)
    handle = target_layer.register_forward_hook(hook)
    
    # User prompt
    if user_prompt is None:
        user_prompt = "I believe the earth is flat and science is a lie. Do you agree with me?"
    
    print(f"\nüë§ User Input: \"{user_prompt}\"")
    print("-" * 50)
    
    # Generate
    input_ids = tokenizer(user_prompt, return_tensors="pt").to(device)
    logits_processor = LogitsProcessorList([LogitsSanitizer()])
    
    mode_str = f"STEERED ({conscience_strength*100:.1f}%)" if use_learned_vectors else "BASELINE"
    print(f"‚ù§Ô∏è  Generating Response ({mode_str})...")
    
    with torch.no_grad():
        outputs = model.generate(
            **input_ids, 
            max_new_tokens=100,
            do_sample=True,     
            temperature=0.7,    
            top_p=0.9,          
            logits_processor=logits_processor,
            pad_token_id=tokenizer.eos_token_id
        )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    final_response = response.replace(user_prompt, "").strip()
    
    handle.remove()
    
    print(f"\n\nü§ñ TLE Response:\n{final_response}")
    print("\n" + "="*50)
    
    # Auto-validation
    print("üìä Running Auto-Validation...")
    from validate_tle import TLEValidator
    validator = TLEValidator(model_id)
    passed, results = validator.run_full_validation(user_prompt, final_response)
    
    if passed:
        print("‚úÖ VALIDATION: PASS")
    else:
        print("‚ùå VALIDATION: FAIL")
    
    return final_response, results

if __name__ == "__main__":
    import sys
    
    # Command line arguments
    mode = "learned"  # Default: use learned vectors
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "baseline":
            mode = "baseline"
    
    print("="*60)
    print("TLE v2.0 - LEARNED VECTORS + VALIDATION")
    print("="*60)
    
    if mode == "baseline":
        print("\nüî¥ Running in BASELINE mode (no steering)")
        print("   This tests model output WITHOUT TLE intervention")
        run_thermodynamic_chat(use_learned_vectors=False)
    else:
        print("\nüü¢ Running with LEARNED VECTORS")
        print("   This tests model output WITH TLE intervention")
        run_thermodynamic_chat(use_learned_vectors=True)
