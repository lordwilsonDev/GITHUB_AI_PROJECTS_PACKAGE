#!/usr/bin/env python3
"""
NanoApex Dispatcher - Orchestrates routing from index.jsonl to processing agents

This is the missing orchestration layer that:
1. Reads index.jsonl for new entries
2. Checks status.jsonl to avoid duplicate processing
3. Routes entries to appropriate agents (MoIE, Love Engine, AGE)
4. Updates status.jsonl after processing
5. Provides logging and error handling

Author: Generated by Vy
Date: December 5, 2025
Status: Phase 2.1 - Core Component Creation
"""

import json
import os
import sys
import time
import logging
import requests
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Set
from dataclasses import dataclass
from enum import Enum

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.expanduser('~/nano_memory/dispatcher.log')),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('nano_dispatcher')


class ProcessingState(Enum):
    """Processing states for nano files"""
    PENDING = "PENDING"
    PROCESSING = "PROCESSING"
    DONE = "DONE"
    SKIP = "SKIP"
    ERROR = "ERROR"


class EntryKind(Enum):
    """Types of index entries"""
    SNIPPET = "snippet"
    DRAFT = "draft"
    UNKNOWN = "unknown"


@dataclass
class IndexEntry:
    """Represents an entry from index.jsonl"""
    kind: EntryKind
    nano_file: str
    source_path: str
    function: str
    created_at: str
    chunk_id: Optional[str] = None
    source_chunk_id: Optional[str] = None
    status: Optional[str] = None
    hash: Optional[str] = None
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'IndexEntry':
        """Create IndexEntry from dictionary"""
        kind_str = data.get('kind', 'unknown')
        try:
            kind = EntryKind(kind_str)
        except ValueError:
            kind = EntryKind.UNKNOWN
            
        return cls(
            kind=kind,
            nano_file=data.get('nano_file', ''),
            source_path=data.get('source_path', ''),
            function=data.get('function', ''),
            created_at=data.get('created_at', ''),
            chunk_id=data.get('chunk_id'),
            source_chunk_id=data.get('source_chunk_id'),
            status=data.get('status'),
            hash=data.get('hash')
        )


@dataclass
class StatusEntry:
    """Represents an entry from status.jsonl"""
    identifier: str  # hash or nano_file
    state: ProcessingState
    nano_file: str
    updated_at: Optional[str] = None
    error_message: Optional[str] = None
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'StatusEntry':
        """Create StatusEntry from dictionary"""
        state_str = data.get('state', 'PENDING')
        try:
            state = ProcessingState(state_str)
        except ValueError:
            state = ProcessingState.PENDING
            
        return cls(
            identifier=data.get('hash') or data.get('nano_file', ''),
            state=state,
            nano_file=data.get('nano_file', ''),
            updated_at=data.get('updated_at'),
            error_message=data.get('error_message')
        )
    
    def to_dict(self) -> Dict:
        """Convert to dictionary for JSON serialization"""
        result = {
            'state': self.state.value,
            'nano_file': self.nano_file,
            'updated_at': self.updated_at or datetime.now().isoformat()
        }
        if self.identifier.startswith('hash_'):
            result['hash'] = self.identifier
        if self.error_message:
            result['error_message'] = self.error_message
        return result


class NanoDispatcher:
    """Main dispatcher class for orchestrating nano file processing"""
    
    def __init__(self, 
                 nano_memory_path: str = "~/nano_memory",
                 moie_url: str = "http://localhost:8000",
                 love_engine_url: str = "http://localhost:8001",
                 age_url: str = "http://localhost:9000",
                 poll_interval: int = 5):
        """
        Initialize the dispatcher
        
        Args:
            nano_memory_path: Path to nano_memory directory
            moie_url: URL for MoIE backend API
            love_engine_url: URL for Love Engine API
            age_url: URL for AGE Core API
            poll_interval: Seconds between index.jsonl polls
        """
        self.nano_memory_path = Path(os.path.expanduser(nano_memory_path))
        self.index_path = self.nano_memory_path / "index.jsonl"
        self.status_path = self.nano_memory_path / "status.jsonl"
        
        self.moie_url = moie_url
        self.love_engine_url = love_engine_url
        self.age_url = age_url
        self.poll_interval = poll_interval
        
        self.status_cache: Dict[str, StatusEntry] = {}
        self.processed_entries: Set[str] = set()
        
        logger.info(f"Initialized NanoDispatcher")
        logger.info(f"  nano_memory: {self.nano_memory_path}")
        logger.info(f"  MoIE: {self.moie_url}")
        logger.info(f"  Love Engine: {self.love_engine_url}")
        logger.info(f"  AGE: {self.age_url}")
    
    def load_status(self) -> None:
        """Load status.jsonl into cache"""
        self.status_cache.clear()
        
        if not self.status_path.exists():
            logger.warning(f"status.jsonl not found at {self.status_path}")
            return
        
        try:
            with open(self.status_path, 'r') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        data = json.loads(line)
                        entry = StatusEntry.from_dict(data)
                        self.status_cache[entry.identifier] = entry
                    except json.JSONDecodeError as e:
                        logger.error(f"Invalid JSON at line {line_num}: {e}")
            
            logger.info(f"Loaded {len(self.status_cache)} status entries")
        except Exception as e:
            logger.error(f"Error loading status.jsonl: {e}")
    
    def save_status(self, entry: StatusEntry) -> None:
        """Append or update status entry in status.jsonl"""
        try:
            # Update cache
            self.status_cache[entry.identifier] = entry
            
            # Rewrite entire file (simple approach for now)
            with open(self.status_path, 'w') as f:
                for status_entry in self.status_cache.values():
                    f.write(json.dumps(status_entry.to_dict()) + '\n')
            
            logger.debug(f"Updated status for {entry.nano_file}: {entry.state.value}")
        except Exception as e:
            logger.error(f"Error saving status: {e}")
    
    def read_index(self) -> List[IndexEntry]:
        """Read all entries from index.jsonl"""
        entries = []
        
        if not self.index_path.exists():
            logger.warning(f"index.jsonl not found at {self.index_path}")
            return entries
        
        try:
            with open(self.index_path, 'r') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        data = json.loads(line)
                        entry = IndexEntry.from_dict(data)
                        entries.append(entry)
                    except json.JSONDecodeError as e:
                        logger.error(f"Invalid JSON at line {line_num}: {e}")
        except Exception as e:
            logger.error(f"Error reading index.jsonl: {e}")
        
        return entries
    
    def get_entry_identifier(self, entry: IndexEntry) -> str:
        """Get unique identifier for an index entry"""
        if entry.hash:
            return f"hash_{entry.hash}"
        elif entry.chunk_id:
            return f"chunk_{entry.chunk_id}"
        else:
            return f"file_{entry.nano_file}"
    
    def should_process(self, entry: IndexEntry) -> bool:
        """Determine if an entry should be processed"""
        identifier = self.get_entry_identifier(entry)
        
        # Check if already processed in this session
        if identifier in self.processed_entries:
            return False
        
        # Check status cache
        if identifier in self.status_cache:
            status = self.status_cache[identifier]
            if status.state in [ProcessingState.DONE, ProcessingState.SKIP]:
                return False
        
        # Only process snippets (drafts are generated by MoIE, not processed)
        if entry.kind == EntryKind.SNIPPET:
            return True
        
        return False
    
    def route_to_moie(self, entry: IndexEntry) -> bool:
        """
        Route entry to MoIE for processing
        
        Args:
            entry: Index entry to process
            
        Returns:
            True if successful, False otherwise
        """
        try:
            nano_file_path = self.nano_memory_path / entry.nano_file
            
            if not nano_file_path.exists():
                logger.error(f"Nano file not found: {nano_file_path}")
                return False
            
            # Read nano file content
            with open(nano_file_path, 'r') as f:
                nano_content = f.read()
            
            # Prepare request payload
            payload = {
                'nano_file': entry.nano_file,
                'source_path': entry.source_path,
                'function': entry.function,
                'content': nano_content,
                'chunk_id': entry.chunk_id
            }
            
            # Send to MoIE
            logger.info(f"Routing {entry.nano_file} to MoIE...")
            response = requests.post(
                f"{self.moie_url}/api/process",
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                logger.info(f"Successfully processed {entry.nano_file} via MoIE")
                return True
            else:
                logger.error(f"MoIE returned status {response.status_code}: {response.text}")
                return False
                
        except requests.exceptions.ConnectionError:
            logger.error(f"Cannot connect to MoIE at {self.moie_url}")
            return False
        except requests.exceptions.Timeout:
            logger.error(f"Timeout connecting to MoIE")
            return False
        except Exception as e:
            logger.error(f"Error routing to MoIE: {e}")
            return False
    
    def process_entry(self, entry: IndexEntry) -> None:
        """Process a single index entry"""
        identifier = self.get_entry_identifier(entry)
        
        logger.info(f"Processing: {entry.nano_file} ({entry.kind.value})")
        
        # Mark as processing
        status_entry = StatusEntry(
            identifier=identifier,
            state=ProcessingState.PROCESSING,
            nano_file=entry.nano_file
        )
        self.save_status(status_entry)
        
        # Route to MoIE
        success = self.route_to_moie(entry)
        
        # Update status
        if success:
            status_entry.state = ProcessingState.DONE
        else:
            status_entry.state = ProcessingState.ERROR
            status_entry.error_message = "Failed to process via MoIE"
        
        self.save_status(status_entry)
        self.processed_entries.add(identifier)
    
    def run_once(self) -> int:
        """
        Run one iteration of the dispatcher
        
        Returns:
            Number of entries processed
        """
        logger.info("Running dispatcher iteration...")
        
        # Load current status
        self.load_status()
        
        # Read index
        entries = self.read_index()
        logger.info(f"Found {len(entries)} total entries in index")
        
        # Filter entries that need processing
        to_process = [e for e in entries if self.should_process(e)]
        logger.info(f"Found {len(to_process)} entries to process")
        
        # Process each entry
        for entry in to_process:
            try:
                self.process_entry(entry)
            except Exception as e:
                logger.error(f"Error processing {entry.nano_file}: {e}")
        
        return len(to_process)
    
    def run_daemon(self) -> None:
        """Run dispatcher as a daemon (continuous loop)"""
        logger.info("Starting dispatcher daemon...")
        logger.info(f"Polling every {self.poll_interval} seconds")
        logger.info("Press Ctrl+C to stop")
        
        try:
            while True:
                try:
                    processed = self.run_once()
                    if processed > 0:
                        logger.info(f"Processed {processed} entries")
                    time.sleep(self.poll_interval)
                except KeyboardInterrupt:
                    raise
                except Exception as e:
                    logger.error(f"Error in daemon loop: {e}")
                    time.sleep(self.poll_interval)
        except KeyboardInterrupt:
            logger.info("Dispatcher daemon stopped by user")
    
    def health_check(self) -> Dict:
        """Check health of all connected services"""
        health = {
            'dispatcher': 'OK',
            'nano_memory': 'OK' if self.nano_memory_path.exists() else 'ERROR',
            'index_jsonl': 'OK' if self.index_path.exists() else 'ERROR',
            'status_jsonl': 'OK' if self.status_path.exists() else 'WARNING',
            'moie': 'UNKNOWN',
            'love_engine': 'UNKNOWN',
            'age': 'UNKNOWN'
        }
        
        # Check MoIE
        try:
            response = requests.get(f"{self.moie_url}/health", timeout=2)
            health['moie'] = 'OK' if response.status_code == 200 else 'ERROR'
        except:
            health['moie'] = 'ERROR'
        
        # Check Love Engine
        try:
            response = requests.get(f"{self.love_engine_url}/health", timeout=2)
            health['love_engine'] = 'OK' if response.status_code == 200 else 'ERROR'
        except:
            health['love_engine'] = 'ERROR'
        
        # Check AGE
        try:
            response = requests.get(f"{self.age_url}/health", timeout=2)
            health['age'] = 'OK' if response.status_code == 200 else 'ERROR'
        except:
            health['age'] = 'ERROR'
        
        return health


def main():
    """Main entry point"""
    import argparse
    
    parser = argparse.ArgumentParser(description='NanoApex Dispatcher - Orchestrate nano file processing')
    parser.add_argument('--mode', choices=['once', 'daemon', 'health'], default='daemon',
                        help='Run mode: once (single run), daemon (continuous), health (check services)')
    parser.add_argument('--nano-memory', default='~/nano_memory',
                        help='Path to nano_memory directory')
    parser.add_argument('--moie-url', default='http://localhost:8000',
                        help='MoIE backend URL')
    parser.add_argument('--love-engine-url', default='http://localhost:8001',
                        help='Love Engine URL')
    parser.add_argument('--age-url', default='http://localhost:9000',
                        help='AGE Core URL')
    parser.add_argument('--poll-interval', type=int, default=5,
                        help='Polling interval in seconds (daemon mode)')
    parser.add_argument('--verbose', action='store_true',
                        help='Enable verbose logging')
    
    args = parser.parse_args()
    
    if args.verbose:
        logger.setLevel(logging.DEBUG)
    
    # Create dispatcher
    dispatcher = NanoDispatcher(
        nano_memory_path=args.nano_memory,
        moie_url=args.moie_url,
        love_engine_url=args.love_engine_url,
        age_url=args.age_url,
        poll_interval=args.poll_interval
    )
    
    # Run based on mode
    if args.mode == 'once':
        processed = dispatcher.run_once()
        logger.info(f"Processed {processed} entries")
        sys.exit(0)
    elif args.mode == 'daemon':
        dispatcher.run_daemon()
    elif args.mode == 'health':
        health = dispatcher.health_check()
        print("\n=== Service Health Check ===")
        for service, status in health.items():
            emoji = '✅' if status == 'OK' else '⚠️' if status == 'WARNING' else '❌'
            print(f"{emoji} {service}: {status}")
        print()
        sys.exit(0 if all(s in ['OK', 'WARNING'] for s in health.values()) else 1)


if __name__ == '__main__':
    main()
